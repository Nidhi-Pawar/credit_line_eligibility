{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import joblib\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# For displaying all of the columns in dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#For ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "df0 = pd.read_csv(r\"C:\\Users\\hp\\OneDrive\\Documents\\GitHub\\credit_line_eligibility\\data\\cleaned_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>dti</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>mort_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11.44</td>\n",
       "      <td>10</td>\n",
       "      <td>141326</td>\n",
       "      <td>1.202703</td>\n",
       "      <td>117413</td>\n",
       "      <td>1</td>\n",
       "      <td>2094</td>\n",
       "      <td>1.089146</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>41.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11.99</td>\n",
       "      <td>4</td>\n",
       "      <td>173740</td>\n",
       "      <td>0.060161</td>\n",
       "      <td>117413</td>\n",
       "      <td>1</td>\n",
       "      <td>207128</td>\n",
       "      <td>0.623256</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681703</td>\n",
       "      <td>53.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15600.0</td>\n",
       "      <td>36</td>\n",
       "      <td>10.49</td>\n",
       "      <td>0</td>\n",
       "      <td>141326</td>\n",
       "      <td>-0.796125</td>\n",
       "      <td>117893</td>\n",
       "      <td>1</td>\n",
       "      <td>73637</td>\n",
       "      <td>-0.513208</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079328</td>\n",
       "      <td>92.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>36</td>\n",
       "      <td>6.49</td>\n",
       "      <td>6</td>\n",
       "      <td>141326</td>\n",
       "      <td>-0.319423</td>\n",
       "      <td>117413</td>\n",
       "      <td>1</td>\n",
       "      <td>73637</td>\n",
       "      <td>-2.120210</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.739714</td>\n",
       "      <td>21.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24375.0</td>\n",
       "      <td>60</td>\n",
       "      <td>17.27</td>\n",
       "      <td>9</td>\n",
       "      <td>173740</td>\n",
       "      <td>-0.281432</td>\n",
       "      <td>111005</td>\n",
       "      <td>0</td>\n",
       "      <td>73637</td>\n",
       "      <td>1.893119</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927930</td>\n",
       "      <td>69.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  term  int_rate  emp_length  home_ownership  annual_inc  \\\n",
       "0    10000.0    36     11.44          10          141326    1.202703   \n",
       "1     8000.0    36     11.99           4          173740    0.060161   \n",
       "2    15600.0    36     10.49           0          141326   -0.796125   \n",
       "3     7200.0    36      6.49           6          141326   -0.319423   \n",
       "4    24375.0    60     17.27           9          173740   -0.281432   \n",
       "\n",
       "   verification_status  loan_status  purpose       dti  open_acc  pub_rec  \\\n",
       "0               117413            1     2094  1.089146      16.0      0.0   \n",
       "1               117413            1   207128  0.623256      17.0      0.0   \n",
       "2               117893            1    73637 -0.513208      13.0      0.0   \n",
       "3               117413            1    73637 -2.120210       6.0      0.0   \n",
       "4               111005            0    73637  1.893119      13.0      0.0   \n",
       "\n",
       "   revol_bal  revol_util  total_acc  mort_acc  \n",
       "0   1.434536        41.8       25.0       0.0  \n",
       "1   0.681703        53.3       27.0       3.0  \n",
       "2   0.079328        92.2       26.0       0.0  \n",
       "3  -0.739714        21.5       13.0       0.0  \n",
       "4   0.927930        69.8       43.0       1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346311, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df0.drop(columns=['loan_status'])\n",
    "X.reset_index(inplace=True, drop=True)\n",
    "y = df0['loan_status']\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split data before standardization\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit & transform on training data\n",
    "X_test_scaled = scaler.transform(X_test)  # Only transform test data (NO fitting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({1: 224616, 0: 52432})\n",
      "After SMOTE: Counter({0: 224616, 1: 224616})\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE on the standardized training set\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", Counter(y_train))  \n",
    "print(\"After SMOTE:\", Counter(y_train_resampled)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_resampled = X_test_scaled \n",
    "y_test_resampled = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution: [224616 224616]\n",
      "Test class distribution: [56155 56155]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Train class distribution:\", np.bincount(y_train_resampled))  # Train data target class distribution fter SMOTE\n",
    "print(\"Test class distribution:\", np.bincount(y_test_resampled))  # Test data target class distribution after SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-23 23:27:56,453] A new study created in memory with name: no-name-3954e4b9-edce-476e-b7c0-f249021b7b4d\n",
      "[I 2025-03-23 23:27:58,875] Trial 0 finished with value: 0.6786992545319713 and parameters: {'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 3, 'max_features': 'log2'}. Best is trial 0 with value: 0.6786992545319713.\n",
      "[I 2025-03-23 23:28:10,338] Trial 1 finished with value: 0.7893296435232611 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 1 with value: 0.7893296435232611.\n",
      "[I 2025-03-23 23:28:46,966] Trial 2 finished with value: 0.77899176294587 and parameters: {'n_estimators': 450, 'max_depth': 12, 'min_samples_split': 5, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.7893296435232611.\n",
      "[I 2025-03-23 23:29:20,298] Trial 3 finished with value: 0.7916289156687217 and parameters: {'n_estimators': 350, 'max_depth': 15, 'min_samples_split': 9, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:29:57,044] Trial 4 finished with value: 0.7653587309256793 and parameters: {'n_estimators': 450, 'max_depth': 10, 'min_samples_split': 6, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:30:32,737] Trial 5 finished with value: 0.7567559144159304 and parameters: {'n_estimators': 450, 'max_depth': 9, 'min_samples_split': 2, 'max_features': 'log2'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:30:48,078] Trial 6 finished with value: 0.7661546387331326 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 6, 'max_features': 'log2'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:30:50,732] Trial 7 finished with value: 0.7188155445806343 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 7, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:31:00,196] Trial 8 finished with value: 0.7849083409880498 and parameters: {'n_estimators': 100, 'max_depth': 14, 'min_samples_split': 8, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:31:07,492] Trial 9 finished with value: 0.7636224106322407 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:31:34,306] Trial 10 finished with value: 0.7836176342228638 and parameters: {'n_estimators': 300, 'max_depth': 13, 'min_samples_split': 10, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:32:05,348] Trial 11 finished with value: 0.7933657127506177 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:32:35,563] Trial 12 finished with value: 0.7916870370356648 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 9, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:32:51,567] Trial 13 finished with value: 0.7803136125925559 and parameters: {'n_estimators': 200, 'max_depth': 12, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:33:23,498] Trial 14 finished with value: 0.7828491209955697 and parameters: {'n_estimators': 350, 'max_depth': 13, 'min_samples_split': 8, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:33:38,189] Trial 15 finished with value: 0.7484276589066101 and parameters: {'n_estimators': 250, 'max_depth': 8, 'min_samples_split': 2, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:34:10,072] Trial 16 finished with value: 0.7912796381630751 and parameters: {'n_estimators': 350, 'max_depth': 15, 'min_samples_split': 5, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:34:21,720] Trial 17 finished with value: 0.7244712532178568 and parameters: {'n_estimators': 250, 'max_depth': 6, 'min_samples_split': 7, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:34:48,454] Trial 18 finished with value: 0.7804867011289687 and parameters: {'n_estimators': 300, 'max_depth': 12, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:35:23,451] Trial 19 finished with value: 0.783392821332026 and parameters: {'n_estimators': 400, 'max_depth': 13, 'min_samples_split': 9, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:35:42,069] Trial 20 finished with value: 0.7893269670536007 and parameters: {'n_estimators': 200, 'max_depth': 14, 'min_samples_split': 5, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:36:17,070] Trial 21 finished with value: 0.7916289156687217 and parameters: {'n_estimators': 350, 'max_depth': 15, 'min_samples_split': 9, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:36:45,811] Trial 22 finished with value: 0.7884866892634097 and parameters: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 9, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:37:23,420] Trial 23 finished with value: 0.7923260884401004 and parameters: {'n_estimators': 400, 'max_depth': 15, 'min_samples_split': 8, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:37:53,436] Trial 24 finished with value: 0.7722205747448287 and parameters: {'n_estimators': 400, 'max_depth': 11, 'min_samples_split': 8, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:38:31,731] Trial 25 finished with value: 0.7890481246861669 and parameters: {'n_estimators': 400, 'max_depth': 14, 'min_samples_split': 7, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:38:41,992] Trial 26 finished with value: 0.6759793473567767 and parameters: {'n_estimators': 300, 'max_depth': 3, 'min_samples_split': 10, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:39:08,669] Trial 27 finished with value: 0.7818399360743926 and parameters: {'n_estimators': 250, 'max_depth': 13, 'min_samples_split': 8, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:39:53,438] Trial 28 finished with value: 0.7365717187498511 and parameters: {'n_estimators': 400, 'max_depth': 7, 'min_samples_split': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:40:02,023] Trial 29 finished with value: 0.6747721664865933 and parameters: {'n_estimators': 250, 'max_depth': 3, 'min_samples_split': 6, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-Score: 0.7933657127506177\n",
      "Best Hyperparameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 4, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Reduce dataset size for trials\n",
    "X_train_sample, y_train_sample = resample(X_train_resampled, y_train_resampled, n_samples=70000, random_state=42, stratify=y_train_resampled)\n",
    "\n",
    "rf_X_train, rf_X_val, rf_y_train, rf_y_val = train_test_split(\n",
    "    X_train_sample, y_train_sample, test_size=0.3, random_state=42, stratify=y_train_sample)\n",
    "\n",
    "# Define Optuna objective function\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 450, step=50)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    # min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"])\n",
    "\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        criterion=\"gini\",\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        ccp_alpha=0,\n",
    "        max_features=max_features,\n",
    "        # min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Cross-validation with pruning\n",
    "    cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "    score = cross_val_score(rf, rf_X_train, rf_y_train, \n",
    "                            cv=cv, scoring=\"f1\").mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# Use TPESampler for faster trials\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=30)\n",
    "print(\"Best F1-Score:\", study.best_value)\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8027\n",
      "Precision: 0.7795\n",
      "Recall: 0.8443\n",
      "F1-score: 0.8106\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79     56155\n",
      "           1       0.78      0.84      0.81     56155\n",
      "\n",
      "    accuracy                           0.80    112310\n",
      "   macro avg       0.80      0.80      0.80    112310\n",
      "weighted avg       0.80      0.80      0.80    112310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train RF with best parameters\n",
    "rf_best_params = study.best_params\n",
    "# rf_best = RandomForestClassifier(class_weight=\"balanced\",**rf_best_params, random_state=42, n_jobs=-1)\n",
    "rf_best = RandomForestClassifier(n_estimators=450, max_depth=15, min_samples_split=2, max_features='log2', random_state=42, n_jobs=-1, )\n",
    "rf_best.fit(X_train_resampled, y_train_resampled)\n",
    "# joblib.dump(rf, 'rf_model.pkl')\n",
    "\n",
    "# # Evaluate on validation set\n",
    "y_pred = rf_best.predict(X_test_resampled)\n",
    "rf_preds = rf_best.predict_proba(rf_X_val)[:, 1]\n",
    "\n",
    "# Step 3: Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test_resampled, y_pred)\n",
    "precision = precision_score(y_test_resampled, y_pred, average=\"binary\")  \n",
    "recall = recall_score(y_test_resampled, y_pred, average=\"binary\")  \n",
    "f1 = f1_score(y_test_resampled, y_pred, average=\"binary\")  \n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Full classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_resampled, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-23 23:49:25,321] A new study created in memory with name: no-name-0aaded34-f144-4e3a-b91a-81f3cb3ddb19\n",
      "[I 2025-03-23 23:49:37,393] Trial 0 finished with value: 0.8698095238095238 and parameters: {'learning_rate': 0.17164585799609702, 'max_depth': 3, 'min_child_weight': 4, 'gamma': 0.1663809904508759, 'subsample': 0.8529723780595613, 'colsample_bytree': 0.7626704544140603, 'lambda': 1.8490638687045047, 'alpha': 5.082865735735715}. Best is trial 0 with value: 0.8698095238095238.\n",
      "[I 2025-03-23 23:49:51,483] Trial 1 finished with value: 0.8755714285714286 and parameters: {'learning_rate': 0.04914497686858078, 'max_depth': 9, 'min_child_weight': 3, 'gamma': 0.09506709211237088, 'subsample': 0.7680194135457485, 'colsample_bytree': 0.6559431632042786, 'lambda': 0.1149361484163164, 'alpha': 0.03799279121710413}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:49:59,674] Trial 2 finished with value: 0.8717619047619047 and parameters: {'learning_rate': 0.10529272293951839, 'max_depth': 6, 'min_child_weight': 4, 'gamma': 0.0017656457438666937, 'subsample': 0.7807743455478178, 'colsample_bytree': 0.5220374349150861, 'lambda': 0.05720677481492977, 'alpha': 0.14555402723429703}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:09,615] Trial 3 finished with value: 0.835047619047619 and parameters: {'learning_rate': 0.01703148186477319, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.0022267980052121947, 'subsample': 0.6028698637846086, 'colsample_bytree': 0.6942998557204574, 'lambda': 2.3033784787369433, 'alpha': 0.002231190690378376}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:17,086] Trial 4 finished with value: 0.8493809523809523 and parameters: {'learning_rate': 0.021077226793970626, 'max_depth': 5, 'min_child_weight': 6, 'gamma': 0.03318693612034507, 'subsample': 0.8587858340509328, 'colsample_bytree': 0.5597192232669215, 'lambda': 0.4496000459445715, 'alpha': 0.060972423759275016}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:17,797] Trial 5 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:18,190] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:24,100] Trial 7 finished with value: 0.8609523809523809 and parameters: {'learning_rate': 0.06896569981593664, 'max_depth': 3, 'min_child_weight': 4, 'gamma': 0.3279992341859965, 'subsample': 0.754731862370966, 'colsample_bytree': 0.7224770613285993, 'lambda': 2.219587636595709, 'alpha': 0.01757380074234293}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:35,728] Trial 8 finished with value: 0.8517142857142858 and parameters: {'learning_rate': 0.014976700325474353, 'max_depth': 8, 'min_child_weight': 3, 'gamma': 0.0032292916332517896, 'subsample': 0.8539331205671425, 'colsample_bytree': 0.5645834556227488, 'lambda': 0.29527883293089235, 'alpha': 3.6286118275141663}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:40,189] Trial 9 finished with value: 0.8028571428571428 and parameters: {'learning_rate': 0.01894890832694667, 'max_depth': 3, 'min_child_weight': 4, 'gamma': 0.07752637990587607, 'subsample': 0.6937854369637336, 'colsample_bytree': 0.7252283616254814, 'lambda': 0.15071215575155114, 'alpha': 2.7905041147463425}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:40,556] Trial 10 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:40,902] Trial 11 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:41,251] Trial 12 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:41,644] Trial 13 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:42,059] Trial 14 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:42,409] Trial 15 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:42,743] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:43,095] Trial 17 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:56,152] Trial 18 finished with value: 0.8521904761904762 and parameters: {'learning_rate': 0.010983808621445821, 'max_depth': 9, 'min_child_weight': 2, 'gamma': 0.9773327847862145, 'subsample': 0.6408084323288125, 'colsample_bytree': 0.67086815658296, 'lambda': 0.007170388937321882, 'alpha': 0.0010018849990617229}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:56,449] Trial 19 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:56,887] Trial 20 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:57,192] Trial 21 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:57,539] Trial 22 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:57,881] Trial 23 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:58,244] Trial 24 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:58,555] Trial 25 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:58,880] Trial 26 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:59,282] Trial 27 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:59,769] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:51:00,087] Trial 29 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8755714285714286\n",
      "Best Parameters: {'learning_rate': 0.04914497686858078, 'max_depth': 9, 'min_child_weight': 3, 'gamma': 0.09506709211237088, 'subsample': 0.7680194135457485, 'colsample_bytree': 0.6559431632042786, 'lambda': 0.1149361484163164, 'alpha': 0.03799279121710413}\n"
     ]
    }
   ],
   "source": [
    "from optuna.integration import XGBoostPruningCallback\n",
    "from sklearn.utils import resample\n",
    "\n",
    "X_train_sample, y_train_sample = resample(X_train_resampled, y_train_resampled, n_samples=70000, random_state=42, stratify=y_train_resampled)\n",
    "\n",
    "xgb_X_train, X_val, xgb_y_train, y_val = train_test_split(\n",
    "    X_train_sample, y_train_sample, test_size=0.3, random_state=42, stratify=y_train_sample)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"gpu_hist\",  \n",
    "        \"verbosity\":0,\n",
    "        \"verbose\":-1,\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1.0),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-3, 10.0),\n",
    "        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-3, 10.0),\n",
    "        \"n_estimators\": 500,  # High number for early stopping\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"early_stopping_rounds\":20,\n",
    "        \"callbacks\":[XGBoostPruningCallback(trial, \"validation_0-logloss\")],\n",
    "    }\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(xgb_X_train, xgb_y_train, eval_set=[(X_val, y_val)], verbose=False )\n",
    "\n",
    "    # Predict on validation set\n",
    "    preds = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, preds)\n",
    "    return accuracy\n",
    "\n",
    "# Create study object and optimize\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Accuracy:\", study.best_value)\n",
    "print(\"Best Parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8536\n",
      "Precision: 0.8106\n",
      "Recall: 0.9227\n",
      "F1-score: 0.8630\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84     56155\n",
      "           1       0.81      0.92      0.86     56155\n",
      "\n",
      "    accuracy                           0.85    112310\n",
      "   macro avg       0.86      0.85      0.85    112310\n",
      "weighted avg       0.86      0.85      0.85    112310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train final model using best params on full training data\n",
    "xgb_best_params = study.best_params\n",
    "\n",
    "xgb_best = xgb.XGBClassifier(**xgb_best_params)\n",
    "xgb=xgb_best.fit(X_train_resampled, y_train_resampled)\n",
    "joblib.dump(xgb, 'xgb_model.pkl')\n",
    "\n",
    "y_pred = xgb_best.predict(X_test_resampled)\n",
    "xgb_preds = xgb_best.predict_proba(X_val)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test_resampled, y_pred)\n",
    "precision = precision_score(y_test_resampled, y_pred)\n",
    "recall = recall_score(y_test_resampled, y_pred)\n",
    "f1 = f1_score(y_test_resampled, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Optional: Full classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_resampled, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-25 22:27:49,870] A new study created in memory with name: no-name-cb593c3e-d56e-4a5b-b7ab-c527e72d608d\n",
      "[I 2025-03-25 22:27:54,272] Trial 0 finished with value: 0.9236420045351473 and parameters: {'learning_rate': 0.06295044768921668, 'num_leaves': 200, 'max_depth': 10, 'min_data_in_leaf': 130, 'lambda_l1': 1.816754679275512, 'lambda_l2': 0.036136792903205324, 'feature_fraction': 0.9803471138649004, 'bagging_fraction': 0.8373364230247342, 'bagging_freq': 2}. Best is trial 0 with value: 0.9236420045351473.\n",
      "[I 2025-03-25 22:27:56,485] Trial 1 finished with value: 0.9238811337868481 and parameters: {'learning_rate': 0.2504067674218118, 'num_leaves': 220, 'max_depth': 15, 'min_data_in_leaf': 128, 'lambda_l1': 0.44913822453361957, 'lambda_l2': 0.3248667230936505, 'feature_fraction': 0.42411493084447155, 'bagging_fraction': 0.48909543099533254, 'bagging_freq': 4}. Best is trial 1 with value: 0.9238811337868481.\n",
      "[I 2025-03-25 22:28:02,600] Trial 2 finished with value: 0.9291271383219954 and parameters: {'learning_rate': 0.08856555865286657, 'num_leaves': 180, 'max_depth': 13, 'min_data_in_leaf': 60, 'lambda_l1': 0.12828016123977848, 'lambda_l2': 0.8960949496852882, 'feature_fraction': 0.9309750827147022, 'bagging_fraction': 0.7804673808912908, 'bagging_freq': 3}. Best is trial 2 with value: 0.9291271383219954.\n",
      "[I 2025-03-25 22:28:04,322] Trial 3 finished with value: 0.9056036371882088 and parameters: {'learning_rate': 0.129880142413084, 'num_leaves': 280, 'max_depth': 3, 'min_data_in_leaf': 25, 'lambda_l1': 0.4260836963852838, 'lambda_l2': 0.01739087193168099, 'feature_fraction': 0.40222967413866567, 'bagging_fraction': 0.7308824590105376, 'bagging_freq': 7}. Best is trial 2 with value: 0.9291271383219954.\n",
      "[I 2025-03-25 22:28:06,144] Trial 4 finished with value: 0.9098390975056689 and parameters: {'learning_rate': 0.062288593048007664, 'num_leaves': 360, 'max_depth': 6, 'min_data_in_leaf': 80, 'lambda_l1': 0.001903373465457555, 'lambda_l2': 8.826774441137617, 'feature_fraction': 0.7389653640446967, 'bagging_fraction': 0.8765229016584195, 'bagging_freq': 6}. Best is trial 2 with value: 0.9291271383219954.\n",
      "[I 2025-03-25 22:28:07,722] Trial 5 finished with value: 0.7992284716553288 and parameters: {'learning_rate': 0.011617614677289275, 'num_leaves': 220, 'max_depth': 3, 'min_data_in_leaf': 144, 'lambda_l1': 0.07803070582747651, 'lambda_l2': 0.0414816149631564, 'feature_fraction': 0.5338500337784092, 'bagging_fraction': 0.655103693386226, 'bagging_freq': 4}. Best is trial 2 with value: 0.9291271383219954.\n",
      "[I 2025-03-25 22:28:11,534] Trial 6 finished with value: 0.9299478820861676 and parameters: {'learning_rate': 0.13017363093629963, 'num_leaves': 80, 'max_depth': 11, 'min_data_in_leaf': 20, 'lambda_l1': 0.038182875155758925, 'lambda_l2': 0.04826814484734831, 'feature_fraction': 0.8635007293075874, 'bagging_fraction': 0.8786707414577123, 'bagging_freq': 2}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:14,265] Trial 7 finished with value: 0.9262751020408163 and parameters: {'learning_rate': 0.1850312783573771, 'num_leaves': 320, 'max_depth': 6, 'min_data_in_leaf': 11, 'lambda_l1': 2.5232618308319457, 'lambda_l2': 0.35364536813644215, 'feature_fraction': 0.9287594395754081, 'bagging_fraction': 0.6261628007864797, 'bagging_freq': 4}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:16,531] Trial 8 finished with value: 0.8399256281179139 and parameters: {'learning_rate': 0.023066439060366577, 'num_leaves': 320, 'max_depth': 4, 'min_data_in_leaf': 179, 'lambda_l1': 0.0016293915378022652, 'lambda_l2': 0.0014581999764088336, 'feature_fraction': 0.9868000719013569, 'bagging_fraction': 0.7118205083492084, 'bagging_freq': 6}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:19,782] Trial 9 finished with value: 0.923954485260771 and parameters: {'learning_rate': 0.10556802006532243, 'num_leaves': 200, 'max_depth': 12, 'min_data_in_leaf': 194, 'lambda_l1': 1.3603867138550514, 'lambda_l2': 4.844246045459211, 'feature_fraction': 0.8445836223256623, 'bagging_fraction': 0.5742594760010494, 'bagging_freq': 6}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:22,863] Trial 10 finished with value: 0.8916447029478458 and parameters: {'learning_rate': 0.0312388229773243, 'num_leaves': 20, 'max_depth': 9, 'min_data_in_leaf': 52, 'lambda_l1': 0.01757836508226685, 'lambda_l2': 0.00444985398018422, 'feature_fraction': 0.6909683905621279, 'bagging_fraction': 0.9858704475992115, 'bagging_freq': 1}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:26,549] Trial 11 finished with value: 0.9280314285714285 and parameters: {'learning_rate': 0.10028868645905142, 'num_leaves': 80, 'max_depth': 14, 'min_data_in_leaf': 71, 'lambda_l1': 0.02416236578955564, 'lambda_l2': 1.2361717639046161, 'feature_fraction': 0.8094361578274968, 'bagging_fraction': 0.8520236778141368, 'bagging_freq': 2}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:30,890] Trial 12 finished with value: 0.9215136507936509 and parameters: {'learning_rate': 0.04126146591674678, 'num_leaves': 120, 'max_depth': 12, 'min_data_in_leaf': 37, 'lambda_l1': 0.013931146930728151, 'lambda_l2': 0.4059289190769305, 'feature_fraction': 0.8615206516103224, 'bagging_fraction': 0.9748014500035518, 'bagging_freq': 3}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:34,236] Trial 13 finished with value: 0.9288558911564626 and parameters: {'learning_rate': 0.17191852227778454, 'num_leaves': 120, 'max_depth': 12, 'min_data_in_leaf': 92, 'lambda_l1': 0.11102805938598427, 'lambda_l2': 0.1168367959497802, 'feature_fraction': 0.6482066928742483, 'bagging_fraction': 0.7674775947118105, 'bagging_freq': 1}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:37,027] Trial 14 finished with value: 0.9276016054421768 and parameters: {'learning_rate': 0.2928168588013239, 'num_leaves': 20, 'max_depth': 9, 'min_data_in_leaf': 55, 'lambda_l1': 0.09149508852790321, 'lambda_l2': 1.7470754467907477, 'feature_fraction': 0.8921981943630736, 'bagging_fraction': 0.8990935198975327, 'bagging_freq': 3}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:41,179] Trial 15 finished with value: 0.9268915192743764 and parameters: {'learning_rate': 0.08286205867800357, 'num_leaves': 140, 'max_depth': 13, 'min_data_in_leaf': 10, 'lambda_l1': 9.53944158091035, 'lambda_l2': 0.1251183918544922, 'feature_fraction': 0.7743290767113393, 'bagging_fraction': 0.7984747750863969, 'bagging_freq': 2}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:44,542] Trial 16 finished with value: 0.9291807891156462 and parameters: {'learning_rate': 0.15937288764461113, 'num_leaves': 80, 'max_depth': 11, 'min_data_in_leaf': 46, 'lambda_l1': 0.006686300826705641, 'lambda_l2': 1.5663274518105483, 'feature_fraction': 0.6229222050773364, 'bagging_fraction': 0.928177976702119, 'bagging_freq': 3}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:47,958] Trial 17 finished with value: 0.9287882448979592 and parameters: {'learning_rate': 0.15153720171423968, 'num_leaves': 60, 'max_depth': 10, 'min_data_in_leaf': 35, 'lambda_l1': 0.004907941911711117, 'lambda_l2': 0.008486676777726854, 'feature_fraction': 0.6270602372317943, 'bagging_fraction': 0.9306152652391015, 'bagging_freq': 5}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:50,710] Trial 18 finished with value: 0.9278249795918367 and parameters: {'learning_rate': 0.20646037874183126, 'num_leaves': 80, 'max_depth': 7, 'min_data_in_leaf': 108, 'lambda_l1': 0.004714385726087168, 'lambda_l2': 3.1659738541767295, 'feature_fraction': 0.55275918339627, 'bagging_fraction': 0.93213634714834, 'bagging_freq': 2}. Best is trial 6 with value: 0.9299478820861676.\n",
      "[I 2025-03-25 22:28:53,738] Trial 19 finished with value: 0.9262400816326531 and parameters: {'learning_rate': 0.1352045073895347, 'num_leaves': 160, 'max_depth': 8, 'min_data_in_leaf': 39, 'lambda_l1': 0.006400108146965494, 'lambda_l2': 0.058249775161425495, 'feature_fraction': 0.6048185002452342, 'bagging_fraction': 0.48084206431663956, 'bagging_freq': 3}. Best is trial 6 with value: 0.9299478820861676.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC-AUC Score: 0.9299478820861676\n",
      "Best Parameters: {'learning_rate': 0.13017363093629963, 'num_leaves': 80, 'max_depth': 11, 'min_data_in_leaf': 20, 'lambda_l1': 0.038182875155758925, 'lambda_l2': 0.04826814484734831, 'feature_fraction': 0.8635007293075874, 'bagging_fraction': 0.8786707414577123, 'bagging_freq': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from optuna.pruners import HyperbandPruner\n",
    "\n",
    "# Step 1: Create a fixed validation set (50K rows)\n",
    "X_train_sample, y_train_sample = resample(X_train_resampled, y_train_resampled, n_samples=70000, random_state=42, stratify=y_train_resampled)\n",
    "\n",
    "lgb_X_train, lgb_X_val, lgb_y_train, lgb_y_val = train_test_split(\n",
    "    X_train_sample, y_train_sample, test_size=0.3, random_state=42, stratify=y_train_sample)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param_grid = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"verbose\":-1,\n",
    "        \"boosting_type\": 'gbdt', \n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 400, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 10, 200),\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-3, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-3, 10.0),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(lgb_X_train, label=lgb_y_train)\n",
    "    val_data = lgb.Dataset(lgb_X_val, label=lgb_y_val)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        param_grid,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        valid_names=[\"train\", \"valid_0\"],\n",
    "        callbacks=[lgb.early_stopping(50, verbose=False), lgb.log_evaluation(0)],\n",
    "    )\n",
    "    \n",
    "    preds = model.predict(lgb_X_val)\n",
    "    return roc_auc_score(lgb_y_val, preds)\n",
    "    \n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=HyperbandPruner)\n",
    "study.optimize(objective, n_trials=20)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best ROC-AUC Score:\", study.best_value)\n",
    "print(\"Best Parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8102\n",
      "Precision: 0.8243\n",
      "Recall: 0.9734\n",
      "F1-score: 0.8926\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.11      0.18     13108\n",
      "           1       0.82      0.97      0.89     56155\n",
      "\n",
      "    accuracy                           0.81     69263\n",
      "   macro avg       0.66      0.54      0.54     69263\n",
      "weighted avg       0.76      0.81      0.76     69263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train final LightGBM model with best parameters\n",
    "lgb_best_params = study.best_params\n",
    "lgb_best = lgb.LGBMClassifier(**lgb_best_params)\n",
    "lgb_best.fit(X_train_resampled, y_train_resampled)\n",
    "joblib.dump(lgb_best, 'lgbm_model.pkl')\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = lgb_best.predict(X_test_resampled)\n",
    "lgb_preds = lgb_best.predict_proba(lgb_X_val)[:, 1]\n",
    "\n",
    "# Evaluate results\n",
    "accuracy = accuracy_score(y_test_resampled, y_pred)\n",
    "precision = precision_score(y_test_resampled, y_pred)\n",
    "recall = recall_score(y_test_resampled, y_pred)\n",
    "f1 = f1_score(y_test_resampled, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_resampled, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87      7000\n",
      "           1       0.84      0.94      0.88      7000\n",
      "\n",
      "    accuracy                           0.88     14000\n",
      "   macro avg       0.88      0.88      0.88     14000\n",
      "weighted avg       0.88      0.88      0.88     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split your dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_sample, y_train_sample, \n",
    "                                                  test_size=0.2, stratify=y_train_sample, random_state=42)\n",
    "\n",
    "# Base models \n",
    "rf = rf_best\n",
    "xgb = xgb_best\n",
    "lgbm = lgb_best\n",
    "\n",
    "# Meta-learner\n",
    "meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Define the stacking classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf),\n",
    "        ('xgb', xgb),\n",
    "        ('lgbm', lgbm)\n",
    "    ],\n",
    "    final_estimator=meta_learner,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    passthrough=True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacking_clf.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
