{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\GitHub\\credit_line_eligibility\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import joblib\n",
    "\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# For displaying all of the columns in dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#For ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "df0 = pd.read_csv(r\"C:\\Users\\hp\\OneDrive\\Documents\\GitHub\\credit_line_eligibility\\data\\cleaned_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>dti</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>mort_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11.44</td>\n",
       "      <td>10</td>\n",
       "      <td>141326</td>\n",
       "      <td>1.202703</td>\n",
       "      <td>117413</td>\n",
       "      <td>1</td>\n",
       "      <td>2094</td>\n",
       "      <td>1.089146</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.434536</td>\n",
       "      <td>41.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11.99</td>\n",
       "      <td>4</td>\n",
       "      <td>173740</td>\n",
       "      <td>0.060161</td>\n",
       "      <td>117413</td>\n",
       "      <td>1</td>\n",
       "      <td>207128</td>\n",
       "      <td>0.623256</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681703</td>\n",
       "      <td>53.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15600.0</td>\n",
       "      <td>36</td>\n",
       "      <td>10.49</td>\n",
       "      <td>0</td>\n",
       "      <td>141326</td>\n",
       "      <td>-0.796125</td>\n",
       "      <td>117893</td>\n",
       "      <td>1</td>\n",
       "      <td>73637</td>\n",
       "      <td>-0.513208</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079328</td>\n",
       "      <td>92.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>36</td>\n",
       "      <td>6.49</td>\n",
       "      <td>6</td>\n",
       "      <td>141326</td>\n",
       "      <td>-0.319423</td>\n",
       "      <td>117413</td>\n",
       "      <td>1</td>\n",
       "      <td>73637</td>\n",
       "      <td>-2.120210</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.739714</td>\n",
       "      <td>21.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24375.0</td>\n",
       "      <td>60</td>\n",
       "      <td>17.27</td>\n",
       "      <td>9</td>\n",
       "      <td>173740</td>\n",
       "      <td>-0.281432</td>\n",
       "      <td>111005</td>\n",
       "      <td>0</td>\n",
       "      <td>73637</td>\n",
       "      <td>1.893119</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.927930</td>\n",
       "      <td>69.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  term  int_rate  emp_length  home_ownership  annual_inc  \\\n",
       "0    10000.0    36     11.44          10          141326    1.202703   \n",
       "1     8000.0    36     11.99           4          173740    0.060161   \n",
       "2    15600.0    36     10.49           0          141326   -0.796125   \n",
       "3     7200.0    36      6.49           6          141326   -0.319423   \n",
       "4    24375.0    60     17.27           9          173740   -0.281432   \n",
       "\n",
       "   verification_status  loan_status  purpose       dti  open_acc  pub_rec  \\\n",
       "0               117413            1     2094  1.089146      16.0      0.0   \n",
       "1               117413            1   207128  0.623256      17.0      0.0   \n",
       "2               117893            1    73637 -0.513208      13.0      0.0   \n",
       "3               117413            1    73637 -2.120210       6.0      0.0   \n",
       "4               111005            0    73637  1.893119      13.0      0.0   \n",
       "\n",
       "   revol_bal  revol_util  total_acc  mort_acc  \n",
       "0   1.434536        41.8       25.0       0.0  \n",
       "1   0.681703        53.3       27.0       3.0  \n",
       "2   0.079328        92.2       26.0       0.0  \n",
       "3  -0.739714        21.5       13.0       0.0  \n",
       "4   0.927930        69.8       43.0       1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346311, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df0.drop(columns=['loan_status'])\n",
    "X.reset_index(inplace=True, drop=True)\n",
    "y = df0['loan_status']\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split data before standardization\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit & transform on training data\n",
    "X_test_scaled = scaler.transform(X_test)  # Only transform test data (NO fitting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({1: 224616, 0: 52432})\n",
      "After SMOTE: Counter({0: 224616, 1: 224616})\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE on the standardized training set\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", Counter(y_train))  \n",
    "print(\"After SMOTE:\", Counter(y_train_resampled)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_test_resampled, y_test_resampled = smote.fit_resample(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution: [224616 224616]\n",
      "Test class distribution: [56155 56155]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Train class distribution:\", np.bincount(y_train_resampled))  # Train data target class distribution fter SMOTE\n",
    "print(\"Test class distribution:\", np.bincount(y_test_resampled))  # Test data target class distribution after SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-23 23:27:56,453] A new study created in memory with name: no-name-3954e4b9-edce-476e-b7c0-f249021b7b4d\n",
      "[I 2025-03-23 23:27:58,875] Trial 0 finished with value: 0.6786992545319713 and parameters: {'n_estimators': 50, 'max_depth': 3, 'min_samples_split': 3, 'max_features': 'log2'}. Best is trial 0 with value: 0.6786992545319713.\n",
      "[I 2025-03-23 23:28:10,338] Trial 1 finished with value: 0.7893296435232611 and parameters: {'n_estimators': 100, 'max_depth': 15, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 1 with value: 0.7893296435232611.\n",
      "[I 2025-03-23 23:28:46,966] Trial 2 finished with value: 0.77899176294587 and parameters: {'n_estimators': 450, 'max_depth': 12, 'min_samples_split': 5, 'max_features': 'sqrt'}. Best is trial 1 with value: 0.7893296435232611.\n",
      "[I 2025-03-23 23:29:20,298] Trial 3 finished with value: 0.7916289156687217 and parameters: {'n_estimators': 350, 'max_depth': 15, 'min_samples_split': 9, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:29:57,044] Trial 4 finished with value: 0.7653587309256793 and parameters: {'n_estimators': 450, 'max_depth': 10, 'min_samples_split': 6, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:30:32,737] Trial 5 finished with value: 0.7567559144159304 and parameters: {'n_estimators': 450, 'max_depth': 9, 'min_samples_split': 2, 'max_features': 'log2'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:30:48,078] Trial 6 finished with value: 0.7661546387331326 and parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 6, 'max_features': 'log2'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:30:50,732] Trial 7 finished with value: 0.7188155445806343 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 7, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:31:00,196] Trial 8 finished with value: 0.7849083409880498 and parameters: {'n_estimators': 100, 'max_depth': 14, 'min_samples_split': 8, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:31:07,492] Trial 9 finished with value: 0.7636224106322407 and parameters: {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 10, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:31:34,306] Trial 10 finished with value: 0.7836176342228638 and parameters: {'n_estimators': 300, 'max_depth': 13, 'min_samples_split': 10, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.7916289156687217.\n",
      "[I 2025-03-23 23:32:05,348] Trial 11 finished with value: 0.7933657127506177 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:32:35,563] Trial 12 finished with value: 0.7916870370356648 and parameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 9, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:32:51,567] Trial 13 finished with value: 0.7803136125925559 and parameters: {'n_estimators': 200, 'max_depth': 12, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:33:23,498] Trial 14 finished with value: 0.7828491209955697 and parameters: {'n_estimators': 350, 'max_depth': 13, 'min_samples_split': 8, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:33:38,189] Trial 15 finished with value: 0.7484276589066101 and parameters: {'n_estimators': 250, 'max_depth': 8, 'min_samples_split': 2, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:34:10,072] Trial 16 finished with value: 0.7912796381630751 and parameters: {'n_estimators': 350, 'max_depth': 15, 'min_samples_split': 5, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:34:21,720] Trial 17 finished with value: 0.7244712532178568 and parameters: {'n_estimators': 250, 'max_depth': 6, 'min_samples_split': 7, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:34:48,454] Trial 18 finished with value: 0.7804867011289687 and parameters: {'n_estimators': 300, 'max_depth': 12, 'min_samples_split': 4, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:35:23,451] Trial 19 finished with value: 0.783392821332026 and parameters: {'n_estimators': 400, 'max_depth': 13, 'min_samples_split': 9, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:35:42,069] Trial 20 finished with value: 0.7893269670536007 and parameters: {'n_estimators': 200, 'max_depth': 14, 'min_samples_split': 5, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:36:17,070] Trial 21 finished with value: 0.7916289156687217 and parameters: {'n_estimators': 350, 'max_depth': 15, 'min_samples_split': 9, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:36:45,811] Trial 22 finished with value: 0.7884866892634097 and parameters: {'n_estimators': 300, 'max_depth': 14, 'min_samples_split': 9, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:37:23,420] Trial 23 finished with value: 0.7923260884401004 and parameters: {'n_estimators': 400, 'max_depth': 15, 'min_samples_split': 8, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:37:53,436] Trial 24 finished with value: 0.7722205747448287 and parameters: {'n_estimators': 400, 'max_depth': 11, 'min_samples_split': 8, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:38:31,731] Trial 25 finished with value: 0.7890481246861669 and parameters: {'n_estimators': 400, 'max_depth': 14, 'min_samples_split': 7, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:38:41,992] Trial 26 finished with value: 0.6759793473567767 and parameters: {'n_estimators': 300, 'max_depth': 3, 'min_samples_split': 10, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:39:08,669] Trial 27 finished with value: 0.7818399360743926 and parameters: {'n_estimators': 250, 'max_depth': 13, 'min_samples_split': 8, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:39:53,438] Trial 28 finished with value: 0.7365717187498511 and parameters: {'n_estimators': 400, 'max_depth': 7, 'min_samples_split': 3, 'max_features': 'sqrt'}. Best is trial 11 with value: 0.7933657127506177.\n",
      "[I 2025-03-23 23:40:02,023] Trial 29 finished with value: 0.6747721664865933 and parameters: {'n_estimators': 250, 'max_depth': 3, 'min_samples_split': 6, 'max_features': 'log2'}. Best is trial 11 with value: 0.7933657127506177.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1-Score: 0.7933657127506177\n",
      "Best Hyperparameters: {'n_estimators': 300, 'max_depth': 15, 'min_samples_split': 4, 'max_features': 'log2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Reduce dataset size for trials\n",
    "X_train_sample, y_train_sample = resample(X_train_resampled, y_train_resampled, n_samples=70000, random_state=42, stratify=y_train_resampled)\n",
    "\n",
    "rf_X_train, rf_X_val, rf_y_train, rf_y_val = train_test_split(\n",
    "    X_train_sample, y_train_sample, test_size=0.3, random_state=42, stratify=y_train_sample)\n",
    "\n",
    "# Define Optuna objective function\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 450, step=50)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    # min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 10)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\"])\n",
    "\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        criterion=\"gini\",\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        ccp_alpha=0,\n",
    "        max_features=max_features,\n",
    "        # min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Cross-validation with pruning\n",
    "    cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "    score = cross_val_score(rf, rf_X_train, rf_y_train, \n",
    "                            cv=cv, scoring=\"f1\").mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# Use TPESampler for faster trials\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler())\n",
    "study.optimize(objective, n_trials=30)\n",
    "print(\"Best F1-Score:\", study.best_value)\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8027\n",
      "Precision: 0.7795\n",
      "Recall: 0.8443\n",
      "F1-score: 0.8106\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79     56155\n",
      "           1       0.78      0.84      0.81     56155\n",
      "\n",
      "    accuracy                           0.80    112310\n",
      "   macro avg       0.80      0.80      0.80    112310\n",
      "weighted avg       0.80      0.80      0.80    112310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train RF with best parameters\n",
    "rf_best_params = study.best_params\n",
    "# rf_best = RandomForestClassifier(class_weight=\"balanced\",**rf_best_params, random_state=42, n_jobs=-1)\n",
    "rf_best = RandomForestClassifier(n_estimators=450, max_depth=15, min_samples_split=2, max_features='log2', random_state=42, n_jobs=-1, )\n",
    "rf_best.fit(X_train_resampled, y_train_resampled)\n",
    "# joblib.dump(rf, 'rf_model.pkl')\n",
    "\n",
    "# # Evaluate on validation set\n",
    "y_pred = rf_best.predict(X_test_resampled)\n",
    "rf_preds = rf_best.predict_proba(rf_X_val)[:, 1]\n",
    "\n",
    "# Step 3: Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test_resampled, y_pred)\n",
    "precision = precision_score(y_test_resampled, y_pred, average=\"binary\")  \n",
    "recall = recall_score(y_test_resampled, y_pred, average=\"binary\")  \n",
    "f1 = f1_score(y_test_resampled, y_pred, average=\"binary\")  \n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Full classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_resampled, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-23 23:49:25,321] A new study created in memory with name: no-name-0aaded34-f144-4e3a-b91a-81f3cb3ddb19\n",
      "[I 2025-03-23 23:49:37,393] Trial 0 finished with value: 0.8698095238095238 and parameters: {'learning_rate': 0.17164585799609702, 'max_depth': 3, 'min_child_weight': 4, 'gamma': 0.1663809904508759, 'subsample': 0.8529723780595613, 'colsample_bytree': 0.7626704544140603, 'lambda': 1.8490638687045047, 'alpha': 5.082865735735715}. Best is trial 0 with value: 0.8698095238095238.\n",
      "[I 2025-03-23 23:49:51,483] Trial 1 finished with value: 0.8755714285714286 and parameters: {'learning_rate': 0.04914497686858078, 'max_depth': 9, 'min_child_weight': 3, 'gamma': 0.09506709211237088, 'subsample': 0.7680194135457485, 'colsample_bytree': 0.6559431632042786, 'lambda': 0.1149361484163164, 'alpha': 0.03799279121710413}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:49:59,674] Trial 2 finished with value: 0.8717619047619047 and parameters: {'learning_rate': 0.10529272293951839, 'max_depth': 6, 'min_child_weight': 4, 'gamma': 0.0017656457438666937, 'subsample': 0.7807743455478178, 'colsample_bytree': 0.5220374349150861, 'lambda': 0.05720677481492977, 'alpha': 0.14555402723429703}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:09,615] Trial 3 finished with value: 0.835047619047619 and parameters: {'learning_rate': 0.01703148186477319, 'max_depth': 5, 'min_child_weight': 2, 'gamma': 0.0022267980052121947, 'subsample': 0.6028698637846086, 'colsample_bytree': 0.6942998557204574, 'lambda': 2.3033784787369433, 'alpha': 0.002231190690378376}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:17,086] Trial 4 finished with value: 0.8493809523809523 and parameters: {'learning_rate': 0.021077226793970626, 'max_depth': 5, 'min_child_weight': 6, 'gamma': 0.03318693612034507, 'subsample': 0.8587858340509328, 'colsample_bytree': 0.5597192232669215, 'lambda': 0.4496000459445715, 'alpha': 0.060972423759275016}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:17,797] Trial 5 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:18,190] Trial 6 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:24,100] Trial 7 finished with value: 0.8609523809523809 and parameters: {'learning_rate': 0.06896569981593664, 'max_depth': 3, 'min_child_weight': 4, 'gamma': 0.3279992341859965, 'subsample': 0.754731862370966, 'colsample_bytree': 0.7224770613285993, 'lambda': 2.219587636595709, 'alpha': 0.01757380074234293}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:35,728] Trial 8 finished with value: 0.8517142857142858 and parameters: {'learning_rate': 0.014976700325474353, 'max_depth': 8, 'min_child_weight': 3, 'gamma': 0.0032292916332517896, 'subsample': 0.8539331205671425, 'colsample_bytree': 0.5645834556227488, 'lambda': 0.29527883293089235, 'alpha': 3.6286118275141663}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:40,189] Trial 9 finished with value: 0.8028571428571428 and parameters: {'learning_rate': 0.01894890832694667, 'max_depth': 3, 'min_child_weight': 4, 'gamma': 0.07752637990587607, 'subsample': 0.6937854369637336, 'colsample_bytree': 0.7252283616254814, 'lambda': 0.15071215575155114, 'alpha': 2.7905041147463425}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:40,556] Trial 10 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:40,902] Trial 11 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:41,251] Trial 12 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:41,644] Trial 13 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:42,059] Trial 14 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:42,409] Trial 15 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:42,743] Trial 16 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:43,095] Trial 17 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:56,152] Trial 18 finished with value: 0.8521904761904762 and parameters: {'learning_rate': 0.010983808621445821, 'max_depth': 9, 'min_child_weight': 2, 'gamma': 0.9773327847862145, 'subsample': 0.6408084323288125, 'colsample_bytree': 0.67086815658296, 'lambda': 0.007170388937321882, 'alpha': 0.0010018849990617229}. Best is trial 1 with value: 0.8755714285714286.\n",
      "[I 2025-03-23 23:50:56,449] Trial 19 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:56,887] Trial 20 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:57,192] Trial 21 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:57,539] Trial 22 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:57,881] Trial 23 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:58,244] Trial 24 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:58,555] Trial 25 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:58,880] Trial 26 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:59,282] Trial 27 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:50:59,769] Trial 28 pruned. Trial was pruned at iteration 0.\n",
      "[I 2025-03-23 23:51:00,087] Trial 29 pruned. Trial was pruned at iteration 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.8755714285714286\n",
      "Best Parameters: {'learning_rate': 0.04914497686858078, 'max_depth': 9, 'min_child_weight': 3, 'gamma': 0.09506709211237088, 'subsample': 0.7680194135457485, 'colsample_bytree': 0.6559431632042786, 'lambda': 0.1149361484163164, 'alpha': 0.03799279121710413}\n"
     ]
    }
   ],
   "source": [
    "from optuna.integration import XGBoostPruningCallback\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Step 1: Create a fixed validation set (50K rows)\n",
    "X_train_sample, y_train_sample = resample(X_train_resampled, y_train_resampled, n_samples=70000, random_state=42, stratify=y_train_resampled)\n",
    "\n",
    "xgb_X_train, X_val, xgb_y_train, y_val = train_test_split(\n",
    "    X_train_sample, y_train_sample, test_size=0.3, random_state=42, stratify=y_train_sample)\n",
    "\n",
    "# Step 2: Define the Optuna objective function\n",
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameter search space\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"gpu_hist\",  \n",
    "        \"verbosity\":0,\n",
    "        \"verbose\":-1,\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-3, 1.0),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-3, 10.0),\n",
    "        \"alpha\": trial.suggest_loguniform(\"alpha\", 1e-3, 10.0),\n",
    "        \"n_estimators\": 500,  # High number for early stopping\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"early_stopping_rounds\":20,\n",
    "        \"callbacks\":[XGBoostPruningCallback(trial, \"validation_0-logloss\")],\n",
    "    }\n",
    "    \n",
    "    # pruning_callback = XGBoostPruningCallback(trial, \"validation_0-logloss\")\n",
    "    # Train the model\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(xgb_X_train, xgb_y_train, eval_set=[(X_val, y_val)], verbose=False )\n",
    "\n",
    "    # Predict on validation set\n",
    "    preds = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, preds)\n",
    "    return accuracy\n",
    "\n",
    "# Step 3: Run Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best Accuracy:\", study.best_value)\n",
    "print(\"Best Parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8536\n",
      "Precision: 0.8106\n",
      "Recall: 0.9227\n",
      "F1-score: 0.8630\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84     56155\n",
      "           1       0.81      0.92      0.86     56155\n",
      "\n",
      "    accuracy                           0.85    112310\n",
      "   macro avg       0.86      0.85      0.85    112310\n",
      "weighted avg       0.86      0.85      0.85    112310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train final model using best params on full training data\n",
    "xgb_best_params = study.best_params\n",
    "\n",
    "xgb_best = xgb.XGBClassifier(**xgb_best_params)\n",
    "xgb=xgb_best.fit(X_train_resampled, y_train_resampled)\n",
    "joblib.dump(xgb, 'xgb_model.pkl')\n",
    "\n",
    "y_pred = xgb_best.predict(X_test_resampled)\n",
    "xgb_preds = xgb_best.predict_proba(X_val)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test_resampled, y_pred)\n",
    "precision = precision_score(y_test_resampled, y_pred)\n",
    "recall = recall_score(y_test_resampled, y_pred)\n",
    "f1 = f1_score(y_test_resampled, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Optional: Full classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_resampled, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-23 23:53:07,895] A new study created in memory with name: no-name-b25bc9e1-19e4-46f2-969d-4a29b4c7c0a2\n",
      "[I 2025-03-23 23:53:16,059] Trial 0 finished with value: 0.9274200272108842 and parameters: {'learning_rate': 0.05584472170764126, 'num_leaves': 280, 'max_depth': 11, 'min_data_in_leaf': 28, 'lambda_l1': 0.004397542784986295, 'lambda_l2': 0.0013933404443800933, 'feature_fraction': 0.49653241086684463, 'bagging_fraction': 0.4571894076494749, 'bagging_freq': 3}. Best is trial 0 with value: 0.9274200272108842.\n",
      "[I 2025-03-23 23:53:18,757] Trial 1 finished with value: 0.9101128752834468 and parameters: {'learning_rate': 0.14897308503788276, 'num_leaves': 40, 'max_depth': 3, 'min_data_in_leaf': 166, 'lambda_l1': 0.010760762934719358, 'lambda_l2': 0.0012378398795271862, 'feature_fraction': 0.9944615743321128, 'bagging_fraction': 0.42596074387253374, 'bagging_freq': 1}. Best is trial 0 with value: 0.9274200272108842.\n",
      "[I 2025-03-23 23:53:23,973] Trial 2 finished with value: 0.8989695419501134 and parameters: {'learning_rate': 0.016080873484525166, 'num_leaves': 400, 'max_depth': 11, 'min_data_in_leaf': 47, 'lambda_l1': 0.0013805519456660848, 'lambda_l2': 0.00540564480079783, 'feature_fraction': 0.6679773499742826, 'bagging_fraction': 0.7995327154423529, 'bagging_freq': 1}. Best is trial 0 with value: 0.9274200272108842.\n",
      "[I 2025-03-23 23:53:27,147] Trial 3 finished with value: 0.9097984943310657 and parameters: {'learning_rate': 0.03998441447602772, 'num_leaves': 120, 'max_depth': 11, 'min_data_in_leaf': 188, 'lambda_l1': 0.12438348318731199, 'lambda_l2': 8.992764492966518, 'feature_fraction': 0.6482515037613833, 'bagging_fraction': 0.5911288392907807, 'bagging_freq': 4}. Best is trial 0 with value: 0.9274200272108842.\n",
      "[I 2025-03-23 23:53:30,712] Trial 4 finished with value: 0.876475410430839 and parameters: {'learning_rate': 0.020003308562029386, 'num_leaves': 100, 'max_depth': 10, 'min_data_in_leaf': 143, 'lambda_l1': 0.010217123070378616, 'lambda_l2': 9.3993377286894, 'feature_fraction': 0.9326732556384792, 'bagging_fraction': 0.7118278604012362, 'bagging_freq': 5}. Best is trial 0 with value: 0.9274200272108842.\n",
      "[I 2025-03-23 23:53:32,553] Trial 5 finished with value: 0.9149800544217689 and parameters: {'learning_rate': 0.16355291861564436, 'num_leaves': 380, 'max_depth': 3, 'min_data_in_leaf': 72, 'lambda_l1': 0.014683880485961665, 'lambda_l2': 0.005771390945719512, 'feature_fraction': 0.5182830117312602, 'bagging_fraction': 0.6046107547394447, 'bagging_freq': 3}. Best is trial 0 with value: 0.9274200272108842.\n",
      "[I 2025-03-23 23:53:36,005] Trial 6 finished with value: 0.906502231292517 and parameters: {'learning_rate': 0.02754262371218655, 'num_leaves': 180, 'max_depth': 9, 'min_data_in_leaf': 81, 'lambda_l1': 0.010440194645841375, 'lambda_l2': 0.004538788165024705, 'feature_fraction': 0.46775809942688534, 'bagging_fraction': 0.7623349761512364, 'bagging_freq': 1}. Best is trial 0 with value: 0.9274200272108842.\n",
      "[I 2025-03-23 23:53:38,987] Trial 7 finished with value: 0.9257336417233561 and parameters: {'learning_rate': 0.08235313025398665, 'num_leaves': 260, 'max_depth': 11, 'min_data_in_leaf': 154, 'lambda_l1': 0.4287876383937052, 'lambda_l2': 1.8558797082462133, 'feature_fraction': 0.4943900521082966, 'bagging_fraction': 0.6507526619585537, 'bagging_freq': 6}. Best is trial 0 with value: 0.9274200272108842.\n",
      "[I 2025-03-23 23:53:42,941] Trial 8 finished with value: 0.8878426394557823 and parameters: {'learning_rate': 0.02027093379389709, 'num_leaves': 160, 'max_depth': 12, 'min_data_in_leaf': 136, 'lambda_l1': 0.10884309248146304, 'lambda_l2': 0.1134909812590202, 'feature_fraction': 0.8167128284351748, 'bagging_fraction': 0.6362181383022656, 'bagging_freq': 6}. Best is trial 0 with value: 0.9274200272108842.\n",
      "[I 2025-03-23 23:53:47,955] Trial 9 finished with value: 0.9097159546485262 and parameters: {'learning_rate': 0.029241072311318235, 'num_leaves': 300, 'max_depth': 11, 'min_data_in_leaf': 54, 'lambda_l1': 0.0031005156178380475, 'lambda_l2': 6.6651244336833715, 'feature_fraction': 0.7478345824126496, 'bagging_fraction': 0.9788464648171351, 'bagging_freq': 4}. Best is trial 0 with value: 0.9274200272108842.\n",
      "[I 2025-03-23 23:53:53,708] Trial 10 finished with value: 0.9273868662131519 and parameters: {'learning_rate': 0.07456587218342177, 'num_leaves': 300, 'max_depth': 15, 'min_data_in_leaf': 14, 'lambda_l1': 4.558355877882056, 'lambda_l2': 0.07549987060733276, 'feature_fraction': 0.5878220769948947, 'bagging_fraction': 0.42153433945407953, 'bagging_freq': 3}. Best is trial 0 with value: 0.9274200272108842.\n",
      "[I 2025-03-23 23:53:58,883] Trial 11 finished with value: 0.928048671201814 and parameters: {'learning_rate': 0.07181527308429107, 'num_leaves': 300, 'max_depth': 15, 'min_data_in_leaf': 14, 'lambda_l1': 3.0792694388733275, 'lambda_l2': 0.10494698434572493, 'feature_fraction': 0.5845569080211722, 'bagging_fraction': 0.4143020921461387, 'bagging_freq': 3}. Best is trial 11 with value: 0.928048671201814.\n",
      "[I 2025-03-23 23:54:03,024] Trial 12 finished with value: 0.924959365079365 and parameters: {'learning_rate': 0.05944810268142579, 'num_leaves': 240, 'max_depth': 15, 'min_data_in_leaf': 16, 'lambda_l1': 8.731045503704326, 'lambda_l2': 0.10283105335789772, 'feature_fraction': 0.41251426395128177, 'bagging_fraction': 0.5235226351100442, 'bagging_freq': 3}. Best is trial 11 with value: 0.928048671201814.\n",
      "[I 2025-03-23 23:54:05,894] Trial 13 finished with value: 0.9227900680272109 and parameters: {'learning_rate': 0.2984788599813862, 'num_leaves': 340, 'max_depth': 7, 'min_data_in_leaf': 100, 'lambda_l1': 0.980463404089111, 'lambda_l2': 0.2950884395435657, 'feature_fraction': 0.5749138806383653, 'bagging_fraction': 0.4043780520700681, 'bagging_freq': 2}. Best is trial 11 with value: 0.928048671201814.\n",
      "[I 2025-03-23 23:54:12,738] Trial 14 finished with value: 0.9290236916099773 and parameters: {'learning_rate': 0.10472599203129926, 'num_leaves': 300, 'max_depth': 13, 'min_data_in_leaf': 34, 'lambda_l1': 1.5851860466735266, 'lambda_l2': 0.01831785872517951, 'feature_fraction': 0.4028746801190124, 'bagging_fraction': 0.5062031265497579, 'bagging_freq': 4}. Best is trial 14 with value: 0.9290236916099773.\n",
      "[I 2025-03-23 23:54:17,819] Trial 15 finished with value: 0.9147615419501132 and parameters: {'learning_rate': 0.010167713935080805, 'num_leaves': 340, 'max_depth': 14, 'min_data_in_leaf': 43, 'lambda_l1': 1.4959961470577352, 'lambda_l2': 0.04442295370335761, 'feature_fraction': 0.41700551015412224, 'bagging_fraction': 0.512681981353368, 'bagging_freq': 7}. Best is trial 14 with value: 0.9290236916099773.\n",
      "[I 2025-03-23 23:54:22,248] Trial 16 finished with value: 0.925751455782313 and parameters: {'learning_rate': 0.12475410746233254, 'num_leaves': 220, 'max_depth': 13, 'min_data_in_leaf': 107, 'lambda_l1': 2.577127410095801, 'lambda_l2': 0.018424770132177568, 'feature_fraction': 0.7845156387392852, 'bagging_fraction': 0.5266239312070583, 'bagging_freq': 5}. Best is trial 14 with value: 0.9290236916099773.\n",
      "[I 2025-03-23 23:54:25,549] Trial 17 finished with value: 0.9257619591836735 and parameters: {'learning_rate': 0.10420568422542602, 'num_leaves': 340, 'max_depth': 7, 'min_data_in_leaf': 64, 'lambda_l1': 0.46811873636851836, 'lambda_l2': 0.34463087552299343, 'feature_fraction': 0.5853019431052227, 'bagging_fraction': 0.8789344240991319, 'bagging_freq': 2}. Best is trial 14 with value: 0.9290236916099773.\n",
      "[I 2025-03-23 23:54:30,063] Trial 18 finished with value: 0.9236080181405897 and parameters: {'learning_rate': 0.23141567215658232, 'num_leaves': 180, 'max_depth': 13, 'min_data_in_leaf': 33, 'lambda_l1': 0.32245842520208357, 'lambda_l2': 0.02300319737174138, 'feature_fraction': 0.7138169360158113, 'bagging_fraction': 0.5114991501416672, 'bagging_freq': 5}. Best is trial 14 with value: 0.9290236916099773.\n",
      "[I 2025-03-23 23:54:34,867] Trial 19 finished with value: 0.9267736326530612 and parameters: {'learning_rate': 0.08674171116165019, 'num_leaves': 360, 'max_depth': 14, 'min_data_in_leaf': 88, 'lambda_l1': 0.04473370915848287, 'lambda_l2': 0.4866809115303758, 'feature_fraction': 0.8410835270247856, 'bagging_fraction': 0.4881694880720607, 'bagging_freq': 2}. Best is trial 14 with value: 0.9290236916099773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ROC-AUC Score: 0.9290236916099773\n",
      "Best Parameters: {'learning_rate': 0.10472599203129926, 'num_leaves': 300, 'max_depth': 13, 'min_data_in_leaf': 34, 'lambda_l1': 1.5851860466735266, 'lambda_l2': 0.01831785872517951, 'feature_fraction': 0.4028746801190124, 'bagging_fraction': 0.5062031265497579, 'bagging_freq': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from optuna.pruners import HyperbandPruner\n",
    "\n",
    "# Step 1: Create a fixed validation set (50K rows)\n",
    "X_train_sample, y_train_sample = resample(X_train_resampled, y_train_resampled, n_samples=70000, random_state=42, stratify=y_train_resampled)\n",
    "\n",
    "lgb_X_train, lgb_X_val, lgb_y_train, lgb_y_val = train_test_split(\n",
    "    X_train_sample, y_train_sample, test_size=0.3, random_state=42, stratify=y_train_sample)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param_grid = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"verbose\":-1,\n",
    "        \"boosting_type\": 'gbdt', \n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 400, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 10, 200),\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-3, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-3, 10.0),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "    }\n",
    "    \n",
    "    train_data = lgb.Dataset(lgb_X_train, label=lgb_y_train)\n",
    "    val_data = lgb.Dataset(lgb_X_val, label=lgb_y_val)\n",
    "    \n",
    "    model = lgb.train(\n",
    "        param_grid,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, val_data],\n",
    "        valid_names=[\"train\", \"valid_0\"],\n",
    "        callbacks=[lgb.early_stopping(50, verbose=False), lgb.log_evaluation(0)],\n",
    "    )\n",
    "    \n",
    "    preds = model.predict(lgb_X_val)\n",
    "    return roc_auc_score(lgb_y_val, preds)\n",
    "    \n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"maximize\", pruner=HyperbandPruner)\n",
    "study.optimize(objective, n_trials=20)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best ROC-AUC Score:\", study.best_value)\n",
    "print(\"Best Parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8801\n",
      "Precision: 0.8208\n",
      "Recall: 0.9727\n",
      "F1-score: 0.8903\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87     56155\n",
      "           1       0.82      0.97      0.89     56155\n",
      "\n",
      "    accuracy                           0.88    112310\n",
      "   macro avg       0.89      0.88      0.88    112310\n",
      "weighted avg       0.89      0.88      0.88    112310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train final LightGBM model with best parameters\n",
    "lgb_best_params = study.best_params\n",
    "lgb_best = lgb.LGBMClassifier(**lgb_best_params)\n",
    "lgb_best.fit(X_train_resampled, y_train_resampled)\n",
    "joblib.dump(lgb_best, 'lgbm_model.pkl')\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = lgb_best.predict(X_test_resampled)\n",
    "lgb_preds = lgb_best.predict_proba(lgb_X_val)[:, 1]\n",
    "\n",
    "# Evaluate results\n",
    "accuracy = accuracy_score(y_test_resampled, y_pred)\n",
    "precision = precision_score(y_test_resampled, y_pred)\n",
    "recall = recall_score(y_test_resampled, y_pred)\n",
    "f1 = f1_score(y_test_resampled, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_resampled, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87      7000\n",
      "           1       0.84      0.94      0.88      7000\n",
      "\n",
      "    accuracy                           0.88     14000\n",
      "   macro avg       0.88      0.88      0.88     14000\n",
      "weighted avg       0.88      0.88      0.88     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split your dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_sample, y_train_sample, \n",
    "                                                  test_size=0.2, stratify=y_train_sample, random_state=42)\n",
    "\n",
    "# Base models \n",
    "rf = rf_best\n",
    "xgb = xgb_best\n",
    "lgbm = lgb_best\n",
    "\n",
    "# Meta-learner\n",
    "meta_learner = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Define the stacking classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf),\n",
    "        ('xgb', xgb),\n",
    "        ('lgbm', lgbm)\n",
    "    ],\n",
    "    final_estimator=meta_learner,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    passthrough=True\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = stacking_clf.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
