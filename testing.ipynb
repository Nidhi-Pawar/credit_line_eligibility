{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For displaying all of the columns in dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#For ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(r\"C:\\Users\\hp\\OneDrive\\Documents\\GitHub\\credit_line_eligibility\\data\\credit_eligibility.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value conversions done\n",
      "Null value handling done\n",
      "(370621, 27)\n"
     ]
    }
   ],
   "source": [
    "# Value conversions\n",
    "d = {'10+ years':10, '9 years':9, '8 years':8, '7 years':7, '6 years':6,\n",
    "     '5 years':5, '4 years':4, '3 years':3, '2 years':2,  '1 year':1,\n",
    "     '< 1 year':0 }\n",
    "df0['emp_length']=df0['emp_length'].replace(d)\n",
    "\n",
    "\n",
    "d = {' 36 months':36, ' 60 months':60}\n",
    "df0['term']=df0['term'].replace(d)\n",
    "\n",
    "d = {'Fully Paid':1, 'Charged Off':0}\n",
    "df0['loan_status']=df0['loan_status'].replace(d)\n",
    "print(\"Value conversions done\")\n",
    "\n",
    "# Null value handling\n",
    "\n",
    "mort_avg = df0.groupby('total_acc')['mort_acc'].mean()\n",
    "def mort(total_acc, mort_acc):\n",
    "  if np.isnan(mort_acc):\n",
    "    return mort_avg[total_acc].round()\n",
    "  else:\n",
    "    return mort_acc\n",
    "df0['mort_acc'] = df0.apply(lambda x: mort(x['total_acc'],x['mort_acc']), axis=1)\n",
    "df0.dropna(inplace=True)\n",
    "print(\"Null value handling done\")\n",
    "print(df0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier handling done\n",
      "Columns dropped\n",
      "Frequency encoding done\n",
      "(340971, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>dti</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>mort_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11.44</td>\n",
       "      <td>10.0</td>\n",
       "      <td>139281</td>\n",
       "      <td>117000.0</td>\n",
       "      <td>116404</td>\n",
       "      <td>1</td>\n",
       "      <td>2064</td>\n",
       "      <td>26.24</td>\n",
       "      <td>1.059438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36369.0</td>\n",
       "      <td>-0.515051</td>\n",
       "      <td>0.126558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>171026</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>116404</td>\n",
       "      <td>1</td>\n",
       "      <td>204657</td>\n",
       "      <td>22.05</td>\n",
       "      <td>1.221105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20131.0</td>\n",
       "      <td>-0.024582</td>\n",
       "      <td>0.304191</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15600.0</td>\n",
       "      <td>36</td>\n",
       "      <td>10.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139281</td>\n",
       "      <td>43057.0</td>\n",
       "      <td>115782</td>\n",
       "      <td>1</td>\n",
       "      <td>72570</td>\n",
       "      <td>12.79</td>\n",
       "      <td>0.520816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11987.0</td>\n",
       "      <td>1.618612</td>\n",
       "      <td>0.216455</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>36</td>\n",
       "      <td>6.49</td>\n",
       "      <td>6.0</td>\n",
       "      <td>139281</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>116404</td>\n",
       "      <td>1</td>\n",
       "      <td>72570</td>\n",
       "      <td>2.60</td>\n",
       "      <td>-1.275581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5472.0</td>\n",
       "      <td>-1.389257</td>\n",
       "      <td>-1.193207</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24375.0</td>\n",
       "      <td>60</td>\n",
       "      <td>17.27</td>\n",
       "      <td>9.0</td>\n",
       "      <td>171026</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>108785</td>\n",
       "      <td>0</td>\n",
       "      <td>72570</td>\n",
       "      <td>33.95</td>\n",
       "      <td>0.520816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24584.0</td>\n",
       "      <td>0.674959</td>\n",
       "      <td>1.491152</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  term  int_rate  emp_length  home_ownership  annual_inc  \\\n",
       "0    10000.0    36     11.44        10.0          139281    117000.0   \n",
       "1     8000.0    36     11.99         4.0          171026     65000.0   \n",
       "2    15600.0    36     10.49         0.0          139281     43057.0   \n",
       "3     7200.0    36      6.49         6.0          139281     54000.0   \n",
       "4    24375.0    60     17.27         9.0          171026     55000.0   \n",
       "\n",
       "   verification_status  loan_status  purpose    dti  open_acc  pub_rec  \\\n",
       "0               116404            1     2064  26.24  1.059438      0.0   \n",
       "1               116404            1   204657  22.05  1.221105      0.0   \n",
       "2               115782            1    72570  12.79  0.520816      0.0   \n",
       "3               116404            1    72570   2.60 -1.275581      0.0   \n",
       "4               108785            0    72570  33.95  0.520816      0.0   \n",
       "\n",
       "   revol_bal  revol_util  total_acc  mort_acc  \n",
       "0    36369.0   -0.515051   0.126558       0.0  \n",
       "1    20131.0   -0.024582   0.304191       3.0  \n",
       "2    11987.0    1.618612   0.216455       0.0  \n",
       "3     5472.0   -1.389257  -1.193207       0.0  \n",
       "4    24584.0    0.674959   1.491152       1.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Outlier handling\n",
    "df1 = df0.copy()\n",
    "\n",
    "def iqr_limits(series, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Calculate upper and lower bounds using the IQR method.\n",
    "    \n",
    "    Parameters:\n",
    "    - series: Pandas Series (column) for which to compute IQR limits.\n",
    "    - multiplier: Controls the strictness of outlier detection (default: 1.5).\n",
    "    \n",
    "    Returns:\n",
    "    - (lower_limit, upper_limit): Tuple containing lower and upper bounds.\n",
    "    \"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - multiplier * IQR\n",
    "    upper_limit = Q3 + multiplier * IQR\n",
    "    return lower_limit, upper_limit\n",
    "\n",
    "# 1. IQR method\n",
    "cols = ['loan_amnt', 'int_rate', 'installment']\n",
    "mask = pd.Series(True, index=df1.index)\n",
    "\n",
    "# Calculate the upper and lower limits\n",
    "for col in cols:\n",
    "    ll, ul = iqr_limits(df0[col], multiplier=1.5)\n",
    "    \n",
    "    # Update mask: Mark False where outliers exist in any column\n",
    "    mask &= (df1[col] >= ll) & (df1[col] <= ul)\n",
    "    outliers = df1[(df1[col] < ll) | (df1[col] > ul)]\n",
    "    \n",
    "# Apply the mask to filter out rows with outliers\n",
    "df1 = df1[mask]\n",
    "\n",
    "#2. Quantile capping\n",
    "cols = ['open_acc', 'revol_util', 'total_acc']\n",
    "\n",
    "for col in cols:\n",
    "    lower = df0[col].quantile(0.01)  # 1st percentile\n",
    "    upper = df0[col].quantile(0.99)  # 99th percentile\n",
    "    \n",
    "    df1 = df1[(df1[col] >= lower) & (df1[col] <= upper)]\n",
    "    outliers = df1[(df1[col] < ll) | (df1[col] > ul)]\n",
    "    \n",
    "#3. Yeo-Johnson transformation\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "ols = ['annual_inc', 'revol_bal', 'dti']\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "for col in cols:\n",
    "    df1[col] = pt.fit_transform(df1[[col]])\n",
    "    \n",
    "    # Checking the outlier percentage for transformed columns\n",
    "    ll, ul = iqr_limits(df1[col], multiplier=1.5) \n",
    "    outliers = df1[(df1[col] < ll) | (df1[col] > ul)]\n",
    "    \n",
    "print(\"Outlier handling done\")\n",
    "\n",
    "#Dropping columns\n",
    "\n",
    "df1.drop(columns=['initial_list_status', 'emp_title', 'title','earliest_cr_line', \n",
    "                 'issue_d', 'grade', 'sub_grade', 'installment','pub_rec_bankruptcies', \n",
    "                 'application_type', 'address'], inplace=True)\n",
    "\n",
    "# Get the indices of rows to drop\n",
    "index_to_drop = df1[df1['home_ownership'].isin(['ANY', 'NONE'])].index\n",
    "df1 = df1.drop(index_to_drop)\n",
    "print(\"Columns dropped\")\n",
    "\n",
    "# Frequency encoding\n",
    "cols = ['purpose', 'home_ownership', 'verification_status']\n",
    "for col in cols:\n",
    "    freq_encoding = df1[col].value_counts().to_dict()\n",
    "    df1[col] = df1[col].map(freq_encoding)\n",
    "print(\"Frequency encoding done\")\n",
    "\n",
    "print(df1.shape)\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split done\n",
      "Standardization done\n",
      "SMOTE done\n"
     ]
    }
   ],
   "source": [
    "# Data splitting\n",
    "df0 = df1.copy()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df0.drop(columns=['loan_status'])\n",
    "X.reset_index(inplace=True, drop=True)\n",
    "y = df0['loan_status']\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split data before standardization\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Data split done\")\n",
    "\n",
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit & transform on training data\n",
    "X_test_scaled = scaler.transform(X_test)  # Only transform test data (NO fitting)\n",
    "print(\"Standardization done\")\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "X_test_resampled, y_test_resampled = smote.fit_resample(X_test_scaled, y_test)\n",
    "print(\"SMOTE done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
