{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For displaying all of the columns in dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#For ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(r\"C:\\Users\\hp\\OneDrive\\Documents\\GitHub\\credit_line_eligibility\\data\\credit_eligibility.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value conversions done\n",
      "Null value handling done\n",
      "(370621, 27)\n"
     ]
    }
   ],
   "source": [
    "# Value conversions\n",
    "d = {'10+ years':10, '9 years':9, '8 years':8, '7 years':7, '6 years':6,\n",
    "     '5 years':5, '4 years':4, '3 years':3, '2 years':2,  '1 year':1,\n",
    "     '< 1 year':0 }\n",
    "df0['emp_length']=df0['emp_length'].replace(d)\n",
    "\n",
    "\n",
    "d = {' 36 months':36, ' 60 months':60}\n",
    "df0['term']=df0['term'].replace(d)\n",
    "\n",
    "d = {'Fully Paid':1, 'Charged Off':0}\n",
    "df0['loan_status']=df0['loan_status'].replace(d)\n",
    "print(\"Value conversions done\")\n",
    "\n",
    "# Null value handling\n",
    "if \"mort_acc\" in df0.columns and df0[\"mort_acc\"].isnull().sum() > 0:\n",
    "                    median = df0[\"mort_acc\"].median()\n",
    "                    df0[\"mort_acc\"]=df0[\"mort_acc\"].fillna(median)\n",
    "df0.dropna(inplace=True)\n",
    "print(\"Null value handling done\")\n",
    "print(df0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier handling done\n",
      "(340998, 27)\n",
      "Columns dropped\n",
      "Frequency encoding done\n",
      "(340875, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>purpose</th>\n",
       "      <th>dti</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>revol_bal</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>mort_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11.44</td>\n",
       "      <td>10.0</td>\n",
       "      <td>139281</td>\n",
       "      <td>1.208276</td>\n",
       "      <td>116355</td>\n",
       "      <td>1</td>\n",
       "      <td>2064</td>\n",
       "      <td>1.085578</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.437651</td>\n",
       "      <td>41.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8000.0</td>\n",
       "      <td>36</td>\n",
       "      <td>11.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>171026</td>\n",
       "      <td>0.062010</td>\n",
       "      <td>116355</td>\n",
       "      <td>1</td>\n",
       "      <td>204620</td>\n",
       "      <td>0.618678</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683437</td>\n",
       "      <td>53.3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15600.0</td>\n",
       "      <td>36</td>\n",
       "      <td>10.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139281</td>\n",
       "      <td>-0.797087</td>\n",
       "      <td>115772</td>\n",
       "      <td>1</td>\n",
       "      <td>72545</td>\n",
       "      <td>-0.519602</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079503</td>\n",
       "      <td>92.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7200.0</td>\n",
       "      <td>36</td>\n",
       "      <td>6.49</td>\n",
       "      <td>6.0</td>\n",
       "      <td>139281</td>\n",
       "      <td>-0.318819</td>\n",
       "      <td>116355</td>\n",
       "      <td>1</td>\n",
       "      <td>72545</td>\n",
       "      <td>-2.126816</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.742378</td>\n",
       "      <td>21.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24375.0</td>\n",
       "      <td>60</td>\n",
       "      <td>17.27</td>\n",
       "      <td>9.0</td>\n",
       "      <td>171026</td>\n",
       "      <td>-0.280703</td>\n",
       "      <td>108748</td>\n",
       "      <td>0</td>\n",
       "      <td>72545</td>\n",
       "      <td>1.891590</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.930183</td>\n",
       "      <td>69.8</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt  term  int_rate  emp_length  home_ownership  annual_inc  \\\n",
       "0    10000.0    36     11.44        10.0          139281    1.208276   \n",
       "1     8000.0    36     11.99         4.0          171026    0.062010   \n",
       "2    15600.0    36     10.49         0.0          139281   -0.797087   \n",
       "3     7200.0    36      6.49         6.0          139281   -0.318819   \n",
       "4    24375.0    60     17.27         9.0          171026   -0.280703   \n",
       "\n",
       "   verification_status  loan_status  purpose       dti  open_acc  pub_rec  \\\n",
       "0               116355            1     2064  1.085578      16.0      0.0   \n",
       "1               116355            1   204620  0.618678      17.0      0.0   \n",
       "2               115772            1    72545 -0.519602      13.0      0.0   \n",
       "3               116355            1    72545 -2.126816       6.0      0.0   \n",
       "4               108748            0    72545  1.891590      13.0      0.0   \n",
       "\n",
       "   revol_bal  revol_util  total_acc  mort_acc  \n",
       "0   1.437651        41.8       25.0       0.0  \n",
       "1   0.683437        53.3       27.0       3.0  \n",
       "2   0.079503        92.2       26.0       0.0  \n",
       "3  -0.742378        21.5       13.0       0.0  \n",
       "4   0.930183        69.8       43.0       1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Outlier handling\n",
    "df1 = df0.copy()\n",
    "\n",
    "def iqr_limits(series, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Calculate upper and lower bounds using the IQR method.\n",
    "    \n",
    "    Parameters:\n",
    "    - series: Pandas Series (column) for which to compute IQR limits.\n",
    "    - multiplier: Controls the strictness of outlier detection (default: 1.5).\n",
    "    \n",
    "    Returns:\n",
    "    - (lower_limit, upper_limit): Tuple containing lower and upper bounds.\n",
    "    \"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - multiplier * IQR\n",
    "    upper_limit = Q3 + multiplier * IQR\n",
    "    return lower_limit, upper_limit\n",
    "\n",
    "# 1. IQR method\n",
    "cols = ['loan_amnt', 'int_rate', 'installment']\n",
    "mask = pd.Series(True, index=df1.index)\n",
    "\n",
    "# Calculate the upper and lower limits\n",
    "for col in cols:\n",
    "    ll, ul = iqr_limits(df0[col], multiplier=1.5)\n",
    "    \n",
    "    # Update mask: Mark False where outliers exist in any column\n",
    "    mask &= (df1[col] >= ll) & (df1[col] <= ul)\n",
    "    outliers = df1[(df1[col] < ll) | (df1[col] > ul)]\n",
    "    \n",
    "# Apply the mask to filter out rows with outliers\n",
    "df1 = df1[mask]\n",
    "\n",
    "#2. Quantile capping\n",
    "cols = ['open_acc', 'revol_util', 'total_acc']\n",
    "\n",
    "for col in cols:\n",
    "    lower = df0[col].quantile(0.01)  # 1st percentile\n",
    "    upper = df0[col].quantile(0.99)  # 99th percentile\n",
    "    \n",
    "    df1 = df1[(df1[col] >= lower) & (df1[col] <= upper)]\n",
    "    outliers = df1[(df1[col] < ll) | (df1[col] > ul)]\n",
    "    \n",
    "#3. Yeo-Johnson transformation\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "cols = ['annual_inc', 'revol_bal', 'dti']\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "for col in cols:\n",
    "    df1[col] = pt.fit_transform(df1[[col]])\n",
    "    \n",
    "    # Checking the outlier percentage for transformed columns\n",
    "    ll, ul = iqr_limits(df1[col], multiplier=1.5) \n",
    "    outliers = df1[(df1[col] < ll) | (df1[col] > ul)]\n",
    "    \n",
    "print(\"Outlier handling done\")\n",
    "print(df1.shape)\n",
    "\n",
    "#Dropping columns\n",
    "\n",
    "df1.drop(columns=['initial_list_status', 'emp_title', 'title','earliest_cr_line', \n",
    "                 'issue_d', 'grade', 'sub_grade', 'installment','pub_rec_bankruptcies', \n",
    "                 'application_type', 'address'], inplace=True)\n",
    "\n",
    "# Get the indices of rows to drop\n",
    "index_to_drop = df1[df1['home_ownership'].isin(['ANY', 'NONE', 'OTHER'])].index\n",
    "df1 = df1.drop(index_to_drop)\n",
    "print(\"Columns dropped\")\n",
    "\n",
    "# Frequency encoding\n",
    "cols = ['purpose', 'home_ownership', 'verification_status']\n",
    "for col in cols:\n",
    "    freq_encoding = df1[col].value_counts().to_dict()\n",
    "    df1[col] = df1[col].map(freq_encoding)\n",
    "print(\"Frequency encoding done\")\n",
    "\n",
    "print(df1.shape)\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split done\n",
      "Standardization done\n",
      "SMOTE done\n"
     ]
    }
   ],
   "source": [
    "# Data splitting\n",
    "df0 = df1.copy()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df0.drop(columns=['loan_status'])\n",
    "X.reset_index(inplace=True, drop=True)\n",
    "y = df0['loan_status']\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split data before standardization\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Data split done\")\n",
    "\n",
    "# Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit & transform on training data\n",
    "X_test_scaled = scaler.transform(X_test)  # Only transform test data (NO fitting)\n",
    "print(\"Standardization done\")\n",
    "\n",
    "# SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "X_test_resampled, y_test_resampled = smote.fit_resample(X_test_scaled, y_test)\n",
    "print(\"SMOTE done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
